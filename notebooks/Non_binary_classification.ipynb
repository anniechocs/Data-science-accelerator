{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This follows from the workbook \"New Binary Classification\"\n",
    "## Based on Chapter 3 in O'Reilly book \"Hands on Machine Learning 2\"\n",
    "### We read in the Fasttext embedding already created and apply non-binary classification following the second part of the chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "# imbalanced dataset metrics\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import vectorized CPA data\n",
    "The vectorized columns are as follows:    \n",
    "- Descr_cleaned_vectorized : FastText vectorization of the \"Descr_cleaned\" column\n",
    "- Full_descr_cleaned_vectorized : FastText vectorization of the \"Full_descr_cleaned\" column\n",
    "- Descr_Low_dim : Reduced dimension (UMAP 10 dimensions) of FastText vectorization of the \"Descr_cleaned\" column\n",
    "- Full_descr_Low_dim : Reduced dimension (UMAP 10 dimensions) of FastText vectorization of the \"Full_descr_cleaned\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Code  Level                  Descr_old        Descr Includes  \\\n",
       "5   01.11.11      6                Durum wheat  Durum wheat      NaN   \n",
       "6   01.11.12      6  Wheat, except durum wheat        Wheat      NaN   \n",
       "8   01.11.20      6                      Maize        Maize      NaN   \n",
       "10  01.11.31      6                     Barley       Barley      NaN   \n",
       "11  01.11.32      6                        Rye          Rye      NaN   \n",
       "\n",
       "    Category_0 Category_1  Category_2                 Full_descr  \\\n",
       "5            1          A           1                Durum wheat   \n",
       "6            1          A           1  Wheat, except durum wheat   \n",
       "8            1          A           1                      Maize   \n",
       "10           1          A           1                     Barley   \n",
       "11           1          A           1                        Rye   \n",
       "\n",
       "   Descr_cleaned        Full_descr_cleaned  \\\n",
       "5    durum wheat               durum wheat   \n",
       "6          wheat  wheat except durum wheat   \n",
       "8          maize                     maize   \n",
       "10        barley                    barley   \n",
       "11           rye                       rye   \n",
       "\n",
       "                             Descr_cleaned_vectorized  \\\n",
       "5   [-0.07021299  0.07487412 -0.08852207 -0.093424...   \n",
       "6   [ 6.82471097e-02  5.72879892e-03 -2.74024643e-...   \n",
       "8   [-2.75462180e-01  2.88966715e-01 -1.60463899e-...   \n",
       "10  [-0.48283365 -0.02554321 -0.09297911  0.358175...   \n",
       "11  [-0.23049644  0.07332443 -0.51851004  0.030723...   \n",
       "\n",
       "                        Full_descr_cleaned_vectorized  \\\n",
       "5   [-0.07021299  0.07487412 -0.08852207 -0.093424...   \n",
       "6   [-8.17044750e-02  4.43322510e-02 -1.21796057e-...   \n",
       "8   [-2.75462180e-01  2.88966715e-01 -1.60463899e-...   \n",
       "10  [-0.48283365 -0.02554321 -0.09297911  0.358175...   \n",
       "11  [-0.23049644  0.07332443 -0.51851004  0.030723...   \n",
       "\n",
       "                                        Descr_Low_dim  \\\n",
       "5   [10.613475799560547, 1.6112016439437866, 6.889...   \n",
       "6   [10.610937118530273, 1.6146502494812012, 6.886...   \n",
       "8   [10.598653793334961, 1.5319408178329468, 6.899...   \n",
       "10  [10.606842994689941, 1.6108537912368774, 6.884...   \n",
       "11  [10.645343780517578, 1.672475814819336, 6.8885...   \n",
       "\n",
       "                                   Full_descr_Low_dim  \n",
       "5   [10.080077171325684, 3.1135828495025635, 5.750...  \n",
       "6   [10.07783031463623, 3.1349775791168213, 5.7314...  \n",
       "8   [10.088605880737305, 3.1780178546905518, 5.732...  \n",
       "10  [10.082571983337402, 3.0978615283966064, 5.779...  \n",
       "11  [10.067237854003906, 3.0663797855377197, 5.772...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code</th>\n      <th>Level</th>\n      <th>Descr_old</th>\n      <th>Descr</th>\n      <th>Includes</th>\n      <th>Category_0</th>\n      <th>Category_1</th>\n      <th>Category_2</th>\n      <th>Full_descr</th>\n      <th>Descr_cleaned</th>\n      <th>Full_descr_cleaned</th>\n      <th>Descr_cleaned_vectorized</th>\n      <th>Full_descr_cleaned_vectorized</th>\n      <th>Descr_Low_dim</th>\n      <th>Full_descr_Low_dim</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>01.11.11</td>\n      <td>6</td>\n      <td>Durum wheat</td>\n      <td>Durum wheat</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>Durum wheat</td>\n      <td>durum wheat</td>\n      <td>durum wheat</td>\n      <td>[-0.07021299  0.07487412 -0.08852207 -0.093424...</td>\n      <td>[-0.07021299  0.07487412 -0.08852207 -0.093424...</td>\n      <td>[10.613475799560547, 1.6112016439437866, 6.889...</td>\n      <td>[10.080077171325684, 3.1135828495025635, 5.750...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>01.11.12</td>\n      <td>6</td>\n      <td>Wheat, except durum wheat</td>\n      <td>Wheat</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>Wheat, except durum wheat</td>\n      <td>wheat</td>\n      <td>wheat except durum wheat</td>\n      <td>[ 6.82471097e-02  5.72879892e-03 -2.74024643e-...</td>\n      <td>[-8.17044750e-02  4.43322510e-02 -1.21796057e-...</td>\n      <td>[10.610937118530273, 1.6146502494812012, 6.886...</td>\n      <td>[10.07783031463623, 3.1349775791168213, 5.7314...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01.11.20</td>\n      <td>6</td>\n      <td>Maize</td>\n      <td>Maize</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>Maize</td>\n      <td>maize</td>\n      <td>maize</td>\n      <td>[-2.75462180e-01  2.88966715e-01 -1.60463899e-...</td>\n      <td>[-2.75462180e-01  2.88966715e-01 -1.60463899e-...</td>\n      <td>[10.598653793334961, 1.5319408178329468, 6.899...</td>\n      <td>[10.088605880737305, 3.1780178546905518, 5.732...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>01.11.31</td>\n      <td>6</td>\n      <td>Barley</td>\n      <td>Barley</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>Barley</td>\n      <td>barley</td>\n      <td>barley</td>\n      <td>[-0.48283365 -0.02554321 -0.09297911  0.358175...</td>\n      <td>[-0.48283365 -0.02554321 -0.09297911  0.358175...</td>\n      <td>[10.606842994689941, 1.6108537912368774, 6.884...</td>\n      <td>[10.082571983337402, 3.0978615283966064, 5.779...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>01.11.32</td>\n      <td>6</td>\n      <td>Rye</td>\n      <td>Rye</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>A</td>\n      <td>1</td>\n      <td>Rye</td>\n      <td>rye</td>\n      <td>rye</td>\n      <td>[-0.23049644  0.07332443 -0.51851004  0.030723...</td>\n      <td>[-0.23049644  0.07332443 -0.51851004  0.030723...</td>\n      <td>[10.645343780517578, 1.672475814819336, 6.8885...</td>\n      <td>[10.067237854003906, 3.0663797855377197, 5.772...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# we need to ensure the columns of lists are imported as such\n",
    "import ast\n",
    "generic = lambda x: ast.literal_eval(x)\n",
    "conv = {\n",
    "        'Descr_Low_dim': generic,\n",
    "        'Full_descr_Low_dim': generic}\n",
    "CPA = pd.read_csv('../data/output/CPA_Vectorized.csv', converters=conv)\n",
    "\n",
    "CPA = CPA[CPA.Level==6]\n",
    "CPA = CPA.astype({'Category_0':int,'Category_2':int})\n",
    "CPA.head()\n"
   ]
  },
  {
   "source": [
    "## Split the CPA data into a training and a test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2574, 10) (2574,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[10.24176407,  1.495134  ,  6.934062  ,  5.49697828,  5.47507858,\n",
       "         6.19090939,  9.82301331,  7.17451763,  6.48560524,  4.21679831],\n",
       "       [ 6.43087292,  2.48803687,  1.78880703,  3.02287507,  6.34812403,\n",
       "         3.15756965,  0.56744212,  3.84727097,  6.04655981,  1.59090734]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "def get_test_train(df, Cat, col):\n",
    "    train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    X_train = np.array(list(train_set[col]))\n",
    "    X_test = np.array(list(test_set[col]))\n",
    "    y_train = np.array(list(train_set[Cat]))\n",
    "    y_test = np.array(list(test_set[Cat]))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# we can choose the level of categorisation here, Category_0, _1 or _2, and also the vectorisation to use\n",
    "Cat = 'Category_1'\n",
    "col = 'Descr_Low_dim'\n",
    "X_train, X_test, y_train_cat1, y_test_cat1 = get_test_train(CPA, Cat, col)\n",
    "print(X_train.shape, y_train_cat1.shape)\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2574, 10) (2574,)\n(2574, 10) (2574,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[10.24176407,  1.495134  ,  6.934062  ,  5.49697828,  5.47507858,\n",
       "         6.19090939,  9.82301331,  7.17451763,  6.48560524,  4.21679831],\n",
       "       [ 6.43087292,  2.48803687,  1.78880703,  3.02287507,  6.34812403,\n",
       "         3.15756965,  0.56744212,  3.84727097,  6.04655981,  1.59090734]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# we repeat for Category_0 and Category_2, note that X_train will be the same in each case\n",
    "Cat = 'Category_0'\n",
    "X_train, X_test, y_train_cat0, y_test_cat0 = get_test_train(CPA, Cat, col)\n",
    "print(X_train.shape, y_train_cat0.shape)\n",
    "Cat = 'Category_2'\n",
    "X_train, X_test, y_train_cat2, y_test_cat2 = get_test_train(CPA, Cat, col)\n",
    "print(X_train.shape, y_train_cat2.shape)\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[10.392472267150879,\n",
       " 2.1317131519317627,\n",
       " 7.459656238555908,\n",
       " 6.61699104309082,\n",
       " 4.1032819747924805,\n",
       " 6.102914333343506,\n",
       " 9.116209030151367,\n",
       " 9.040961265563965,\n",
       " 6.673974990844727,\n",
       " 3.864978790283203]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "## To follow the book, let's set up a test item with categories we know\n",
    "test_item = CPA[(CPA.Category_2==10)&(CPA.Category_1=='C')&(CPA.Category_0==2)].Descr_Low_dim[438]\n",
    "test_item"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Binary Classification with Random Forest Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_C,y_scores_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train_cat1, y_train_C, cv=3,\n",
    "                                    method=\"predict_proba\")"
   ]
  },
  {
   "source": [
    "# Imbalanced Data Metrics\n",
    "Our data is imbalanced in the sense that the numbers of items in each class varies a lot.   \n",
    "This section diagresses from the book.\n",
    "\n",
    "NOTE: I had quite a lot of difficulty getting VS Code to recognise imblearn. Finally it worked using !pip install imblearn in jupyter cell directly"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification\n",
    "Whereas binary classifiers distinguish between two classes, multiclass classifiers (also called multinomial classifiers) can distinguish between more than two classes.\n",
    "\n",
    "Some algorithms (such as Logistic Regression classifiers, Random Forest classifiers, and naive Bayes classifiers) are capable of handling multiple classes natively. Others (such as SGD Classifiers or Support Vector Machine classifiers) are strictly binary classifiers. However, there are various strategies that you can use to perform multiclass classification with multiple binary classifiers.\n",
    "\n",
    "** One-versus-rest **   \n",
    "One way to create a system that can classify the digit images into 10 classes (from 0 to 9) is to train 10 binary classifiers, one for each digit (a 0-detector, a 1-detector, a 2-detector, and so on). Then when you want to classify an image, you get the decision score from each classifier for that image and you select the class whose classifier outputs the highest score. This is called the one-versus-the-rest (OvR) strategy (also called one-versus-all).\n",
    "\n",
    "** One-versus-one **   \n",
    "Another strategy is to train a binary classifier for every pair of digits: one to distinguish 0s and 1s, another to distinguish 0s and 2s, another for 1s and 2s, and so on. This is called the one-versus-one (OvO) strategy. If there are N classes, you need to train N × (N – 1) / 2 classifiers. For the MNIST problem, this means training 45 binary classifiers! When you want to classify an image, you have to run the image through all 45 classifiers and see which class wins the most duels. The main advantage of OvO is that each classifier only needs to be trained on the part of the training set for the two classes that it must distinguish.\n",
    "\n",
    "Some algorithms (such as Support Vector Machine classifiers) *scale poorly with the size of the training set*. For these algorithms OvO is preferred because it is faster to train many classifiers on small training sets than to train few classifiers on large training sets. ** For most binary classification algorithms, however, OvR is preferred. **\n"
   ]
  },
  {
   "source": [
    "## Support Vector Machine classifier\n",
    "Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass classification task, and it automatically runs OvR or OvO, depending on the algorithm. Let’s try this with a Support Vector Machine classifier (see Chapter 5), using the sklearn.svm.SVC class:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Under the hood, Scikit-Learn actually used the OvO strategy: it trained N * (N-1) binary classifiers, got their decision scores for the image, and selected the class that won the most duels.\n",
    "\n",
    "If you call the decision_function() method, you will see that it returns N scores per instance (instead of just 1). That’s one score per class (it’s the number of won duels plus or minus a small tweak to break ties, based on the binary classifier scores)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores for Category_0 : target is 2nd \n",
      " [[ 8.29784893  9.30140582  2.73598047  7.27305884  1.72272008  0.71475454\n",
      "  -0.29611218  6.20043305  3.81638767  4.99894874]]\n",
      "Scores for Category_1 : target is 3rd \n",
      " [[19.31761568  9.94805749 20.31813263  6.71574784 12.18839512 10.92955875\n",
      "  18.31215185 16.28514249  4.71007455  8.73576367  3.70409808  1.68890782\n",
      "  15.28555923 17.29297943  2.69948015  5.74240527 13.22725539  7.7599955\n",
      "  14.28103271  0.69076363 -0.31505816]]\n",
      "Scores for Category_1 : target is 3rd \n",
      " [[86.32977312 73.32235829 85.32908422  7.67329075 49.26075995 21.67703709\n",
      "  24.67983317 33.68305329 87.32989489 77.32027593 75.3156973  80.32626072\n",
      "  27.68346952 84.32805105 56.30773453 72.32399326 36.69054155 73.32402056\n",
      "  80.32882196 49.22943733 54.28419396 62.31280486 52.28066299 66.32220154\n",
      "  61.31582348 62.31865833 83.32922604 54.26984546 67.32302221 28.67887789\n",
      "  80.32849547 76.32646244 49.19184403  3.67388919  4.67423176 70.32283417\n",
      "   5.67444593 43.98628358 54.26737476 37.69147784 34.68499953 78.32746455\n",
      "  82.32851182 63.31485819 11.67475617 15.67494405 67.32191163 34.69655469\n",
      "  29.68371334 27.68357175 42.71199689 38.69297095 10.67448086 14.6745286\n",
      "  35.69310846 24.67848986 15.67512279 31.68910616 19.67563367  7.67413595\n",
      "  22.67945348 16.67483328 59.3164035   8.67479748 40.71471746 48.29345101\n",
      "  16.67434155 59.31119739 13.67461573 52.29907031 25.67882637 63.31832961\n",
      "  62.31811169 32.69115457 51.29723701 70.32216824 16.67504756 18.67574243\n",
      "   3.6740446  43.9516548  12.67459962 35.70724997 42.7065383  47.87052375\n",
      "  70.3201169   0.67462421  1.67462408 -0.32779181]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm_clf0 = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf1 = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf2 = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf0.fit(X_train, y_train_cat0)\n",
    "print('Scores for Category_0 : target is 2nd \\n',svm_clf0.decision_function([test_item]))\n",
    "svm_clf1.fit(X_train, y_train_cat1)\n",
    "print('Scores for Category_1 : target is 3rd \\n',svm_clf1.decision_function([test_item]))\n",
    "svm_clf2.fit(X_train, y_train_cat2)\n",
    "print('Scores for Category_1 : target is 3rd \\n',svm_clf2.decision_function([test_item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for Category_0:  [0.85314685 0.84615385 0.85547786]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_1:  [0.82400932 0.82517483 0.81701632]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_2:  [0.57342657 0.53030303 0.55011655]\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for Category_0: ',cross_val_score(svm_clf0, X_train, y_train_cat0, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_1: ',cross_val_score(svm_clf1, X_train, y_train_cat1, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_2: ',cross_val_score(svm_clf2, X_train, y_train_cat2, cv=3, scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  78,    0,   78,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    2,    0,    0],\n",
       "       [   0,    0,   29,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  30,    1, 1330,    0,    0,    1,   15,   14,    0,   14,    0,\n",
       "           0,    2,    3,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    7,    3,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,   11,    0,   47,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,   19,    0,    0,   43,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    2,    1,    0,    0,    0],\n",
       "       [   0,    0,   19,    0,    0,    0,  162,    0,    0,    5,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    4,    0,    0,    0,    0,   77,    1,    4,    1,\n",
       "           0,    1,    8,    0,    0,    1,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    0,    0,   11,    0,    0,\n",
       "           2,    0,    1,    0,    0,    1,    1,    0,    1,    0],\n",
       "       [   0,    0,    8,    0,    0,    0,    0,    0,    0,   96,    0,\n",
       "           0,    4,    0,    0,    0,    2,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    4,    0,    0,    0,   60,\n",
       "           0,    5,    2,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          15,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    5,    0,    0,    0,    1,    3,    0,    9,    6,\n",
       "           0,   81,    6,    0,    0,    1,    1,    0,    0,    0],\n",
       "       [   0,    0,    5,    0,    2,    0,    3,    0,    1,    7,    1,\n",
       "           0,    9,   38,    0,    0,    2,    0,    3,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    3,   18,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,    0,   22,    2,    3,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    2,    0,    0,    0,    0,\n",
       "           0,    3,    1,    0,    0,   29,    0,    0,    0,    0],\n",
       "       [   0,    0,    2,    0,    0,    1,    0,    0,    0,    7,    0,\n",
       "           0,    1,    1,    0,    0,    2,   13,    0,    0,    0],\n",
       "       [   0,    0,   10,    0,    0,    0,    7,    0,    1,    0,    0,\n",
       "           0,    2,    7,    0,    0,    6,    0,    7,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    4,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "y_train_pred_tmp = cross_val_predict(svm_clf1, X_train, y_train_cat1, cv=3)\n",
    "conf_mx_tmp = confusion_matrix(y_train_cat1, y_train_pred_tmp)\n",
    "conf_mx_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          A       0.72      0.49      0.99      0.58      0.70      0.46       159\n",
      "          B       0.00      0.00      1.00      0.00      0.00      0.00        29\n",
      "          C       0.87      0.94      0.83      0.91      0.89      0.79      1410\n",
      "          D       1.00      0.27      1.00      0.43      0.52      0.25        11\n",
      "          E       0.96      0.80      1.00      0.87      0.89      0.78        59\n",
      "          F       0.93      0.65      1.00      0.77      0.81      0.63        66\n",
      "          G       0.83      0.87      0.99      0.85      0.93      0.85       186\n",
      "          H       0.82      0.79      0.99      0.80      0.88      0.76        98\n",
      "          I       0.79      0.61      1.00      0.69      0.78      0.59        18\n",
      "          J       0.67      0.87      0.98      0.76      0.93      0.85       110\n",
      "          K       0.87      0.85      1.00      0.86      0.92      0.83        71\n",
      "          L       0.88      1.00      1.00      0.94      1.00      1.00        15\n",
      "          M       0.72      0.72      0.99      0.72      0.84      0.69       113\n",
      "          N       0.44      0.54      0.98      0.48      0.72      0.50        71\n",
      "          O       0.00      0.00      1.00      0.00      0.00      0.00        22\n",
      "          P       1.00      0.76      1.00      0.86      0.87      0.74        29\n",
      "          Q       0.59      0.83      0.99      0.69      0.91      0.81        35\n",
      "          R       0.68      0.48      1.00      0.57      0.69      0.46        27\n",
      "          S       0.58      0.17      1.00      0.27      0.42      0.16        40\n",
      "          T       0.67      1.00      1.00      0.80      1.00      1.00         4\n",
      "          U       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.81      0.82      0.90      0.81      0.84      0.73      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_train_cat1, y_train_pred_tmp))"
   ]
  },
  {
   "source": [
    "### Repeat this for the Category_0 and Category_2 classifications"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.72      0.49      0.99      0.58      0.70      0.46       159\n",
      "          2       0.91      0.95      0.86      0.93      0.90      0.82      1509\n",
      "          3       0.96      0.67      1.00      0.79      0.82      0.64        66\n",
      "          4       0.78      0.88      0.97      0.83      0.92      0.84       302\n",
      "          5       0.68      0.85      0.98      0.75      0.91      0.82       110\n",
      "          6       0.88      0.85      1.00      0.86      0.92      0.83        71\n",
      "          7       0.94      1.00      1.00      0.97      1.00      1.00        15\n",
      "          8       0.72      0.65      0.98      0.68      0.80      0.61       184\n",
      "          9       0.79      0.74      0.99      0.77      0.86      0.72        86\n",
      "         10       0.67      0.36      0.99      0.47      0.60      0.34        72\n",
      "\n",
      "avg / total       0.85      0.85      0.91      0.85      0.87      0.77      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.63      0.65      0.98      0.64      0.80      0.62       132\n",
      "          2       0.00      0.00      1.00      0.00      0.00      0.00         7\n",
      "          3       0.00      0.00      1.00      0.00      0.00      0.00        20\n",
      "          5       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "          7       0.00      0.00      1.00      0.00      0.00      0.00         7\n",
      "          8       0.00      0.00      1.00      0.00      0.00      0.00        15\n",
      "          9       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "         10       0.55      0.73      0.96      0.63      0.84      0.69       156\n",
      "         11       0.67      0.46      1.00      0.55      0.68      0.44        13\n",
      "         12       0.00      0.00      1.00      0.00      0.00      0.00         4\n",
      "         13       0.48      0.84      0.98      0.61      0.90      0.81        68\n",
      "         14       0.80      0.76      1.00      0.78      0.87      0.74        37\n",
      "         15       0.00      0.00      1.00      0.00      0.00      0.00        24\n",
      "         16       0.46      0.15      1.00      0.23      0.39      0.14        39\n",
      "         17       0.58      0.62      0.99      0.60      0.78      0.59        47\n",
      "         18       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "         19       0.50      0.10      1.00      0.16      0.31      0.09        21\n",
      "         20       0.67      0.81      0.98      0.73      0.89      0.78       140\n",
      "         21       0.00      0.00      1.00      0.00      0.00      0.00        17\n",
      "         22       0.10      0.03      1.00      0.04      0.16      0.02        38\n",
      "         23       0.33      0.69      0.96      0.44      0.81      0.64        70\n",
      "         24       0.70      0.95      0.98      0.80      0.97      0.93        95\n",
      "         25       0.26      0.08      0.99      0.13      0.29      0.08        72\n",
      "         26       0.57      0.83      0.97      0.67      0.90      0.80        99\n",
      "         27       0.78      0.50      1.00      0.61      0.71      0.47        84\n",
      "         28       0.45      0.71      0.93      0.55      0.81      0.65       187\n",
      "         29       0.22      0.17      0.99      0.19      0.41      0.15        30\n",
      "         30       0.35      0.14      1.00      0.20      0.37      0.12        44\n",
      "         31       0.00      0.00      1.00      0.00      0.00      0.00        19\n",
      "         32       0.50      0.05      1.00      0.10      0.23      0.05        55\n",
      "         33       0.88      0.55      1.00      0.68      0.74      0.52        42\n",
      "         35       1.00      0.27      1.00      0.43      0.52      0.25        11\n",
      "         36       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "         37       0.00      0.00      1.00      0.00      0.00      0.00         2\n",
      "         38       0.82      0.82      1.00      0.82      0.90      0.80        49\n",
      "         39       0.00      0.00      1.00      0.00      0.00      0.00         5\n",
      "         41       0.75      0.83      1.00      0.79      0.91      0.82        18\n",
      "         42       1.00      0.04      1.00      0.08      0.21      0.04        23\n",
      "         43       0.68      0.68      1.00      0.68      0.82      0.66        25\n",
      "         45       0.52      0.94      0.99      0.67      0.96      0.92        33\n",
      "         46       0.57      0.88      0.97      0.69      0.93      0.85       100\n",
      "         47       0.00      0.00      1.00      0.00      0.00      0.00        53\n",
      "         49       0.45      0.81      0.99      0.57      0.89      0.78        31\n",
      "         50       0.50      0.85      0.99      0.63      0.92      0.83        20\n",
      "         51       0.00      0.00      1.00      0.00      0.00      0.00        11\n",
      "         52       1.00      0.07      1.00      0.13      0.27      0.06        28\n",
      "         53       1.00      0.25      1.00      0.40      0.50      0.23         8\n",
      "         55       1.00      0.67      1.00      0.80      0.82      0.64         9\n",
      "         56       0.50      0.33      1.00      0.40      0.58      0.31         9\n",
      "         58       0.52      0.85      0.99      0.65      0.92      0.83        41\n",
      "         59       0.37      0.60      0.99      0.45      0.77      0.57        25\n",
      "         60       0.00      0.00      1.00      0.00      0.00      0.00         7\n",
      "         61       0.71      1.00      1.00      0.83      1.00      1.00        17\n",
      "         62       0.00      0.00      1.00      0.00      0.00      0.00        10\n",
      "         63       0.00      0.00      1.00      0.00      0.00      0.00        10\n",
      "         64       0.94      0.65      1.00      0.77      0.81      0.63        23\n",
      "         65       0.57      0.83      0.99      0.68      0.91      0.81        30\n",
      "         66       0.24      0.39      0.99      0.30      0.62      0.36        18\n",
      "         68       0.88      1.00      1.00      0.94      1.00      1.00        15\n",
      "         69       0.00      0.00      1.00      0.00      0.00      0.00        11\n",
      "         70       0.00      0.00      1.00      0.00      0.00      0.00         9\n",
      "         71       0.44      0.74      0.99      0.55      0.86      0.71        23\n",
      "         72       0.84      1.00      1.00      0.92      1.00      1.00        38\n",
      "         73       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "         74       0.19      0.16      0.99      0.17      0.40      0.14        19\n",
      "         75       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "         77       0.56      0.65      1.00      0.60      0.81      0.63        23\n",
      "         78       0.00      0.00      1.00      0.00      0.00      0.00        10\n",
      "         79       0.44      0.36      1.00      0.40      0.60      0.34        11\n",
      "         80       0.00      0.00      1.00      0.00      0.00      0.00         5\n",
      "         81       0.00      0.00      1.00      0.00      0.00      0.00        11\n",
      "         82       0.00      0.00      1.00      0.00      0.00      0.00        11\n",
      "         84       0.39      0.86      0.99      0.54      0.92      0.84        22\n",
      "         85       0.96      0.76      1.00      0.85      0.87      0.74        29\n",
      "         86       1.00      0.62      1.00      0.77      0.79      0.60        16\n",
      "         87       0.00      0.00      1.00      0.00      0.00      0.00         7\n",
      "         88       0.31      0.92      0.99      0.47      0.95      0.90        12\n",
      "         90       0.50      0.20      1.00      0.29      0.45      0.18         5\n",
      "         91       0.00      0.00      1.00      0.00      0.00      0.00         6\n",
      "         92       1.00      0.17      1.00      0.29      0.41      0.15         6\n",
      "         93       0.35      0.60      1.00      0.44      0.77      0.57        10\n",
      "         94       0.79      0.79      1.00      0.79      0.89      0.77        14\n",
      "         95       0.00      0.00      1.00      0.00      0.00      0.00        10\n",
      "         96       0.00      0.00      1.00      0.00      0.00      0.00        16\n",
      "         97       1.00      0.50      1.00      0.67      0.71      0.48         2\n",
      "         98       0.33      0.50      1.00      0.40      0.71      0.47         2\n",
      "         99       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.50      0.55      0.98      0.49      0.66      0.53      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_0 = cross_val_predict(svm_clf0, X_train, y_train_cat0, cv=3)\n",
    "print(classification_report_imbalanced(y_train_cat0, y_train_pred_0))\n",
    "y_train_pred_2 = cross_val_predict(svm_clf2, X_train, y_train_cat2, cv=3)\n",
    "print(classification_report_imbalanced(y_train_cat2, y_train_pred_2))"
   ]
  },
  {
   "source": [
    "## Stochastic Gradient Descent Multi classifier\n",
    "Training an SGDClassifier is just as easy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for Category_0:  [0.68181818 0.79137529 0.72494172]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_1:  [0.75291375 0.71794872 0.74825175]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_2:  [0.28088578 0.16433566 0.21095571]\n"
     ]
    }
   ],
   "source": [
    "sgd_clf0 = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf1 = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf2 = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "sgd_clf0.fit(X_train, y_train_cat0)\n",
    "sgd_clf1.fit(X_train, y_train_cat1)\n",
    "sgd_clf2.fit(X_train, y_train_cat2)\n",
    "\n",
    "print('Accuracy for Category_0: ',cross_val_score(sgd_clf0, X_train, y_train_cat0, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_1: ',cross_val_score(sgd_clf, X_train, y_train_cat1, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_2: ',cross_val_score(sgd_clf2, X_train, y_train_cat2, cv=3, scoring=\"accuracy\"))"
   ]
  },
  {
   "source": [
    "## Improving results using a scaler\n",
    "These results are already a lot better than a random classifier.   \n",
    "QUESTION: since our data is already vectorized, is using this scalar meaningful?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for Category_0:  [0.7972028  0.78088578 0.76223776]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_1:  [0.75058275 0.75641026 0.75291375]\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "\n",
      "Accuracy for Category_2:  [0.35431235 0.41608392 0.38111888]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "print('Accuracy for Category_0: ',cross_val_score(sgd_clf0, X_train_scaled, y_train_cat0, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_1: ',cross_val_score(sgd_clf, X_train_scaled, y_train_cat1, cv=3, scoring=\"accuracy\"))\n",
    "print('\\nAccuracy for Category_2: ',cross_val_score(sgd_clf2, X_train_scaled, y_train_cat2, cv=3, scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  67,    0,   88,    0,    0,    0,    0,    0,    0,    1,    0,\n",
       "           0,    0,    3,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,   27,    1,    0,    0,    0,    1,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  60,    1, 1297,    1,    0,    2,    5,   23,    0,   14,    0,\n",
       "           0,    1,    3,    0,    0,    0,    1,    2,    0,    0],\n",
       "       [   0,    0,    6,    4,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    9,    1,   47,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,   14,    0,    0,   40,    1,    4,    0,    0,    0,\n",
       "           0,    0,    7,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,    0,   57,    0,    0,    0,  123,    0,    0,    5,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,    0,    6,    0,    0,    0,    2,   78,    0,    5,    1,\n",
       "           0,    0,    4,    0,    0,    0,    0,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
       "           0,    0,   13,    0,    0,    0,    0,    3,    1,    0],\n",
       "       [   0,    0,    8,    0,    0,    0,    0,    0,    0,   98,    0,\n",
       "           0,    0,    4,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    4,    0,    0,    0,    0,    1,    0,    1,   55,\n",
       "           0,    0,    9,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    5,\n",
       "           5,    0,    4,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    5,    0,    0,    1,    1,    3,    0,   18,    5,\n",
       "           0,   57,   22,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [   0,    0,    7,    0,    2,    0,   10,    5,    0,    9,    1,\n",
       "           0,    4,   28,    0,    0,    1,    0,    4,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "           0,    2,   15,    0,    0,    0,    0,    4,    0,    0],\n",
       "       [   1,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
       "           0,    0,    5,    0,   21,    0,    0,    1,    0,    0],\n",
       "       [   0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0,\n",
       "           0,    1,   15,    0,    1,   14,    0,    2,    0,    0],\n",
       "       [   0,    0,    2,    0,    0,    7,    0,    0,    0,    7,    0,\n",
       "           0,    1,    9,    0,    0,    0,    1,    0,    0,    0],\n",
       "       [   0,    0,   16,    0,    0,    0,    1,    0,    0,    2,    0,\n",
       "           0,    3,   11,    4,    0,    1,    0,    2,    0,    0],\n",
       "       [   0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    1,    2,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    1,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "y_train_pred_1 = cross_val_predict(sgd_clf1, X_train_scaled, y_train_cat1, cv=3)\n",
    "conf_mx = confusion_matrix(y_train_cat1, y_train_pred_1)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          A       0.52      0.42      0.97      0.46      0.64      0.39       159\n",
      "          B       0.00      0.00      1.00      0.00      0.00      0.00        29\n",
      "          C       0.84      0.92      0.78      0.88      0.85      0.73      1410\n",
      "          D       0.57      0.36      1.00      0.44      0.60      0.34        11\n",
      "          E       0.96      0.80      1.00      0.87      0.89      0.78        59\n",
      "          F       0.77      0.61      1.00      0.68      0.78      0.58        66\n",
      "          G       0.85      0.66      0.99      0.74      0.81      0.63       186\n",
      "          H       0.68      0.80      0.99      0.73      0.89      0.77        98\n",
      "          I       0.00      0.00      1.00      0.00      0.00      0.00        18\n",
      "          J       0.61      0.89      0.97      0.73      0.93      0.86       110\n",
      "          K       0.81      0.77      0.99      0.79      0.88      0.75        71\n",
      "          L       1.00      0.33      1.00      0.50      0.58      0.31        15\n",
      "          M       0.83      0.50      1.00      0.63      0.71      0.48       113\n",
      "          N       0.18      0.39      0.95      0.25      0.61      0.35        71\n",
      "          O       0.00      0.00      1.00      0.00      0.00      0.00        22\n",
      "          P       0.95      0.72      1.00      0.82      0.85      0.70        29\n",
      "          Q       0.88      0.40      1.00      0.55      0.63      0.38        35\n",
      "          R       0.50      0.04      1.00      0.07      0.19      0.03        27\n",
      "          S       0.10      0.05      0.99      0.07      0.22      0.04        40\n",
      "          T       0.50      0.50      1.00      0.50      0.71      0.47         4\n",
      "          U       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.75      0.75      0.88      0.74      0.78      0.64      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_train_cat1, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n\n          1       0.48      0.57      0.96      0.52      0.74      0.52       159\n          2       0.90      0.88      0.87      0.89      0.87      0.77      1509\n          3       0.74      0.64      0.99      0.68      0.80      0.61        66\n          4       0.67      0.79      0.95      0.73      0.87      0.74       302\n          5       0.61      0.86      0.98      0.71      0.92      0.83       110\n          6       0.79      0.85      0.99      0.82      0.92      0.83        71\n          7       1.00      0.33      1.00      0.50      0.58      0.31        15\n          8       0.57      0.48      0.97      0.52      0.68      0.44       184\n          9       0.80      0.57      1.00      0.67      0.75      0.54        86\n         10       0.21      0.14      0.98      0.17      0.37      0.13        72\n\navg / total       0.78      0.78      0.91      0.78      0.83      0.70      2574\n\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_0 = cross_val_predict(sgd_clf0, X_train_scaled, y_train_cat0, cv=3)\n",
    "print(classification_report_imbalanced(y_train_cat0, y_train_pred_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving figure confusion_matrix_plot\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"456.334687pt\" version=\"1.1\" viewBox=\"0 0 475.394 456.334687\" width=\"475.394pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;white-space:pre;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 456.334687 \r\nL 475.394 456.334687 \r\nL 475.394 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 29.47 403.2 \r\nL 386.59 403.2 \r\nL 386.59 46.08 \r\nL 29.47 46.08 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#p60d49e9420)\">\r\n    <image height=\"358\" id=\"imagee4b6b8109d\" transform=\"scale(1 -1)translate(0 -358)\" width=\"358\" x=\"29.47\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-45.2\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mcb92041434\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"37.972857\" xlink:href=\"#mcb92041434\" y=\"403.2\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 -3.5 \r\n\" id=\"m6964cabc19\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"37.972857\" xlink:href=\"#m6964cabc19\" y=\"46.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(34.155357 36.584375)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.001429\" xlink:href=\"#mcb92041434\" y=\"403.2\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.001429\" xlink:href=\"#m6964cabc19\" y=\"46.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(119.183929 36.584375)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.03\" xlink:href=\"#mcb92041434\" y=\"403.2\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.03\" xlink:href=\"#m6964cabc19\" y=\"46.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(200.395 36.584375)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.058571\" xlink:href=\"#mcb92041434\" y=\"403.2\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.058571\" xlink:href=\"#m6964cabc19\" y=\"46.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(285.423571 36.584375)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.087143\" xlink:href=\"#mcb92041434\" y=\"403.2\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.087143\" xlink:href=\"#m6964cabc19\" y=\"46.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(370.452143 36.584375)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_11\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"md860a3da54\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md860a3da54\" y=\"54.582857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(14.835 59.14192)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md860a3da54\" y=\"139.611429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(14.835 144.170491)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md860a3da54\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 229.199062)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md860a3da54\" y=\"309.668571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 314.227634)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#md860a3da54\" y=\"394.697143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 399.256205)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 29.47 403.2 \r\nL 29.47 46.08 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 386.59 403.2 \r\nL 386.59 46.08 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 29.47 403.2 \r\nL 386.59 403.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 29.47 46.08 \r\nL 386.59 46.08 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#p3fd5fe5702)\" d=\"M 408.91 442.08 \r\nL 408.91 440.38125 \r\nL 408.91 8.89875 \r\nL 408.91 7.2 \r\nL 430.654 7.2 \r\nL 430.654 8.89875 \r\nL 430.654 440.38125 \r\nL 430.654 442.08 \r\nz\r\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n   </g>\r\n   <image height=\"435\" id=\"imaged87347ea29\" transform=\"scale(1 -1)translate(0 -435)\" width=\"22\" x=\"409\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAABYAAAGzCAYAAAArEufSAAAABHNCSVQICAgIfAhkiAAAAkVJREFUeJztncGNwzAQAyVbpV0J138pl3tEot0AHwMMCyAWJJeSHSSZP/P3MwpYY14N3tFhHWOsec0KcW9iNQ4xT4oBjFvJvHnhzCtJ0YxbhxspBW3iabuFmBc33sR2xYYTv4hxtUk0z6I/xEDznPgQ2xUbvYk/PfMqvJr3wIkf4laOm2dehxhoHi/Hxu0hxkkBNK8zMLErPtbmRnNBSsQ8KXib543+wKJ/iFsrbW0GSI1bxLhXN5oXYqIUxm0TEy8sHWLjFhi3APkAWSJ28w7cvIAnBW/zeBorRcCLmy9CAl7cgFLwJrYrQqwUB7y4AaXgTax5B6vyrb9h3F6w6AOgeXbFAXBizTsATmy7hVgpDngTa15Qm9gSCnjmASf2XnHggryJO0/Tmhc0zesQa16geYFdEQAvhby44cyrLQjQPCd+EdNqk2eeXfEirvBWfyKsQ6x5gV0RrDE074s1PZo2eBojpegQA4uet3k889y8A2LcSsQ8jYnm4Rbk0rwN5MQl4lYqNC9YV+lxzLgFxi2w6ANg3FpdoXmBEwe9rgBKgTulNe/AiV/E5nijOfFfhZinsXELeHFbN08KYNxK5vFyfGveBq/dkF2heZv4VoqNYrvVih5Xmy0peEXvmRd4rwiacaOZByz6ksbE2sRtXvGUppnHu9ET282i/wIYt9ZKA4ueF7faJ+lE89y8L4D3CqB5uKLv3eg1b4PXbkjzOsQ885pHU4n4BppH+/uDonk8KWgTt+JGlAIYtw43b0HWPXlSwCb+B5UfjmjTopNhAAAAAElFTkSuQmCC\" y=\"-7\"/>\r\n   <g id=\"matplotlib.axis_3\"/>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_16\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 3.5 0 \r\n\" id=\"m69ee87c755\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"442.08\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(437.654 446.639062)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"375.020632\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(437.654 379.579695)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"307.961264\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 400 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 312.520327)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"240.901897\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 600 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 245.460959)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"173.842529\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 800 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 178.401591)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"106.783161\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 1000 -->\r\n      <g transform=\"translate(437.654 111.342224)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m69ee87c755\" y=\"39.723793\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 1200 -->\r\n      <g transform=\"translate(437.654 44.282856)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 408.91 442.08 \r\nL 408.91 440.38125 \r\nL 408.91 8.89875 \r\nL 408.91 7.2 \r\nL 430.654 7.2 \r\nL 430.654 8.89875 \r\nL 430.654 440.38125 \r\nL 430.654 442.08 \r\nz\r\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p60d49e9420\">\r\n   <rect height=\"357.12\" width=\"357.12\" x=\"29.47\" y=\"46.08\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p3fd5fe5702\">\r\n   <rect height=\"434.88\" width=\"21.744\" x=\"408.91\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# since sklearn 0.22, you can use sklearn.metrics.plot_confusion_matrix()\n",
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "#plt.matshow(conf_mx, cmap=plt.cm.gray) # greyscale version\n",
    "plot_confusion_matrix(conf_mx)\n",
    "save_fig(\"confusion_matrix_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving figure confusion_matrix_errors_plot\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"460.89375pt\" version=\"1.1\" viewBox=\"0 0 463.93775 460.89375\" width=\"463.93775pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;white-space:pre;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 460.89375 \r\nL 463.93775 460.89375 \r\nL 463.93775 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 29.47 407.759062 \r\nL 386.59 407.759062 \r\nL 386.59 50.639062 \r\nL 29.47 50.639062 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pcfbcebe4fd)\">\r\n    <image height=\"358\" id=\"imagedd3c7c5a47\" transform=\"scale(1 -1)translate(0 -358)\" width=\"358\" x=\"29.47\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-49.759062\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m95c4fef67d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"37.972857\" xlink:href=\"#m95c4fef67d\" y=\"407.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 -3.5 \r\n\" id=\"mcd63af10be\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"37.972857\" xlink:href=\"#mcd63af10be\" y=\"50.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(34.155357 41.143437)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.001429\" xlink:href=\"#m95c4fef67d\" y=\"407.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.001429\" xlink:href=\"#mcd63af10be\" y=\"50.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(119.183929 41.143437)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.03\" xlink:href=\"#m95c4fef67d\" y=\"407.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.03\" xlink:href=\"#mcd63af10be\" y=\"50.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(200.395 41.143437)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.058571\" xlink:href=\"#m95c4fef67d\" y=\"407.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"293.058571\" xlink:href=\"#mcd63af10be\" y=\"50.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(285.423571 41.143437)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.087143\" xlink:href=\"#m95c4fef67d\" y=\"407.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"378.087143\" xlink:href=\"#mcd63af10be\" y=\"50.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(370.452143 41.143437)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_11\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mea47d7d1bb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#mea47d7d1bb\" y=\"59.14192\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(14.835 63.700982)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#mea47d7d1bb\" y=\"144.170491\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(14.835 148.729554)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#mea47d7d1bb\" y=\"229.199062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 233.758125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#mea47d7d1bb\" y=\"314.227634\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 318.786696)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"29.47\" xlink:href=\"#mea47d7d1bb\" y=\"399.256205\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 403.815268)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 29.47 407.759062 \r\nL 29.47 50.639062 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 386.59 407.759062 \r\nL 386.59 50.639062 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 29.47 407.759062 \r\nL 386.59 407.759062 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 29.47 50.639062 \r\nL 386.59 50.639062 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_7\">\r\n    <path clip-path=\"url(#p72175a2abd)\" d=\"M 408.91 446.639062 \r\nL 408.91 444.940312 \r\nL 408.91 13.457812 \r\nL 408.91 11.759062 \r\nL 430.654 11.759062 \r\nL 430.654 13.457812 \r\nL 430.654 444.940312 \r\nL 430.654 446.639062 \r\nz\r\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n   </g>\r\n   <image height=\"435\" id=\"image6b044f8af9\" transform=\"scale(1 -1)translate(0 -435)\" width=\"22\" x=\"409\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAABYAAAGzCAYAAAArEufSAAAABHNCSVQICAgIfAhkiAAAAkVJREFUeJztncGNwzAQAyVbpV0J138pl3tEot0AHwMMCyAWJJeSHSSZP/P3MwpYY14N3tFhHWOsec0KcW9iNQ4xT4oBjFvJvHnhzCtJ0YxbhxspBW3iabuFmBc33sR2xYYTv4hxtUk0z6I/xEDznPgQ2xUbvYk/PfMqvJr3wIkf4laOm2dehxhoHi/Hxu0hxkkBNK8zMLErPtbmRnNBSsQ8KXib543+wKJ/iFsrbW0GSI1bxLhXN5oXYqIUxm0TEy8sHWLjFhi3APkAWSJ28w7cvIAnBW/zeBorRcCLmy9CAl7cgFLwJrYrQqwUB7y4AaXgTax5B6vyrb9h3F6w6AOgeXbFAXBizTsATmy7hVgpDngTa15Qm9gSCnjmASf2XnHggryJO0/Tmhc0zesQa16geYFdEQAvhby44cyrLQjQPCd+EdNqk2eeXfEirvBWfyKsQ6x5gV0RrDE074s1PZo2eBojpegQA4uet3k889y8A2LcSsQ8jYnm4Rbk0rwN5MQl4lYqNC9YV+lxzLgFxi2w6ANg3FpdoXmBEwe9rgBKgTulNe/AiV/E5nijOfFfhZinsXELeHFbN08KYNxK5vFyfGveBq/dkF2heZv4VoqNYrvVih5Xmy0peEXvmRd4rwiacaOZByz6ksbE2sRtXvGUppnHu9ET282i/wIYt9ZKA4ueF7faJ+lE89y8L4D3CqB5uKLv3eg1b4PXbkjzOsQ885pHU4n4BppH+/uDonk8KWgTt+JGlAIYtw43b0HWPXlSwCb+B5UfjmjTopNhAAAAAElFTkSuQmCC\" y=\"-11\"/>\r\n   <g id=\"matplotlib.axis_3\"/>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_16\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 3.5 0 \r\n\" id=\"m73c6b48ff9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"446.639062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.0 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 451.198125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"359.663062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(437.654 364.222125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"272.687062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.4 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 277.246125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"185.711062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.6 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 190.270125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"98.735062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.8 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(437.654 103.294125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"430.654\" xlink:href=\"#m73c6b48ff9\" y=\"11.759062\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(437.654 16.318125)scale(0.12 -0.12)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 408.91 446.639062 \r\nL 408.91 444.940312 \r\nL 408.91 13.457812 \r\nL 408.91 11.759062 \r\nL 430.654 11.759062 \r\nL 430.654 13.457812 \r\nL 430.654 444.940312 \r\nL 430.654 446.639062 \r\nz\r\n\" style=\"fill:none;stroke:#000000;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pcfbcebe4fd\">\r\n   <rect height=\"357.12\" width=\"357.12\" x=\"29.47\" y=\"50.639062\"/>\r\n  </clipPath>\r\n  <clipPath id=\"p72175a2abd\">\r\n   <rect height=\"434.88\" width=\"21.744\" x=\"408.91\" y=\"11.759062\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "# plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plot_confusion_matrix(norm_conf_mx)\n",
    "save_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Multi Classification for Random Forest\n",
    "the book doesn't deal with this, but states that the Random Forest algorithm is \"capable of handling multiple classes natively.\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:668: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          A       0.83      0.78      0.99      0.80      0.88      0.76       159\n",
      "          B       0.55      0.38      1.00      0.45      0.61      0.35        29\n",
      "          C       0.93      0.95      0.91      0.94      0.93      0.86      1410\n",
      "          D       0.83      0.45      1.00      0.59      0.67      0.43        11\n",
      "          E       0.88      0.83      1.00      0.85      0.91      0.81        59\n",
      "          F       0.91      0.80      1.00      0.85      0.90      0.79        66\n",
      "          G       0.86      0.91      0.99      0.88      0.95      0.89       186\n",
      "          H       0.89      0.88      1.00      0.88      0.93      0.86        98\n",
      "          I       0.88      0.78      1.00      0.82      0.88      0.76        18\n",
      "          J       0.80      0.78      0.99      0.79      0.88      0.76       110\n",
      "          K       0.81      0.85      0.99      0.83      0.92      0.83        71\n",
      "          L       1.00      1.00      1.00      1.00      1.00      1.00        15\n",
      "          M       0.73      0.73      0.99      0.73      0.85      0.70       113\n",
      "          N       0.57      0.52      0.99      0.54      0.72      0.49        71\n",
      "          O       0.48      0.59      0.99      0.53      0.77      0.56        22\n",
      "          P       0.86      0.83      1.00      0.84      0.91      0.81        29\n",
      "          Q       0.79      0.77      1.00      0.78      0.88      0.75        35\n",
      "          R       0.74      0.63      1.00      0.68      0.79      0.61        27\n",
      "          S       0.46      0.45      0.99      0.46      0.67      0.42        40\n",
      "          T       0.67      1.00      1.00      0.80      1.00      1.00         4\n",
      "          U       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.86      0.87      0.95      0.86      0.90      0.81      2574\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.81      0.77      0.99      0.79      0.87      0.74       159\n",
      "          2       0.94      0.96      0.92      0.95      0.94      0.88      1509\n",
      "          3       0.93      0.79      1.00      0.85      0.89      0.77        66\n",
      "          4       0.88      0.89      0.98      0.88      0.94      0.87       302\n",
      "          5       0.83      0.78      0.99      0.80      0.88      0.76       110\n",
      "          6       0.78      0.82      0.99      0.80      0.90      0.80        71\n",
      "          7       1.00      1.00      1.00      1.00      1.00      1.00        15\n",
      "          8       0.70      0.70      0.98      0.70      0.82      0.66       184\n",
      "          9       0.77      0.79      0.99      0.78      0.89      0.77        86\n",
      "         10       0.59      0.53      0.99      0.56      0.72      0.50        72\n",
      "\n",
      "avg / total       0.88      0.89      0.95      0.88      0.91      0.83      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest_clf=RandomForestClassifier(n_estimators=100)\n",
    "y_train_pred_for1 = cross_val_predict(forest_clf, X_train_scaled, y_train_cat1, cv=3)\n",
    "y_train_pred_for0 = cross_val_predict(forest_clf, X_train_scaled, y_train_cat0, cv=3)\n",
    "y_train_pred_for2 = cross_val_predict(forest_clf, X_train_scaled, y_train_cat2, cv=3)\n",
    "\n",
    "print(classification_report_imbalanced(y_train_cat1, y_train_pred_for1))\n",
    "print(classification_report_imbalanced(y_train_cat0, y_train_pred_for0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          1       0.77      0.77      0.99      0.77      0.87      0.74       132\n",
      "          2       0.67      0.29      1.00      0.40      0.53      0.27         7\n",
      "          3       0.71      0.75      1.00      0.73      0.87      0.73        20\n",
      "          5       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "          6       0.00      0.00      1.00      0.00      0.00      0.00         3\n",
      "          7       1.00      0.71      1.00      0.83      0.85      0.69         7\n",
      "          8       0.55      0.80      1.00      0.65      0.89      0.78        15\n",
      "          9       0.67      0.67      1.00      0.67      0.82      0.64         3\n",
      "         10       0.75      0.74      0.98      0.75      0.86      0.71       156\n",
      "         11       0.69      0.69      1.00      0.69      0.83      0.67        13\n",
      "         12       1.00      0.75      1.00      0.86      0.87      0.73         4\n",
      "         13       0.66      0.75      0.99      0.70      0.86      0.72        68\n",
      "         14       0.84      0.86      1.00      0.85      0.93      0.85        37\n",
      "         15       0.68      0.62      1.00      0.65      0.79      0.60        24\n",
      "         16       0.61      0.56      0.99      0.59      0.75      0.54        39\n",
      "         17       0.79      0.70      1.00      0.74      0.84      0.68        47\n",
      "         18       0.50      0.22      1.00      0.31      0.47      0.20         9\n",
      "         19       0.27      0.29      0.99      0.28      0.53      0.26        21\n",
      "         20       0.72      0.72      0.98      0.72      0.84      0.69       140\n",
      "         21       0.57      0.47      1.00      0.52      0.69      0.44        17\n",
      "         22       0.40      0.45      0.99      0.43      0.67      0.42        38\n",
      "         23       0.51      0.53      0.99      0.52      0.72      0.50        70\n",
      "         24       0.85      0.86      0.99      0.86      0.93      0.85        95\n",
      "         25       0.62      0.61      0.99      0.62      0.78      0.58        72\n",
      "         26       0.73      0.79      0.99      0.76      0.88      0.76        99\n",
      "         27       0.74      0.70      0.99      0.72      0.83      0.68        84\n",
      "         28       0.70      0.70      0.98      0.70      0.82      0.66       187\n",
      "         29       0.50      0.50      0.99      0.50      0.71      0.47        30\n",
      "         30       0.61      0.64      0.99      0.62      0.79      0.61        44\n",
      "         31       0.57      0.63      1.00      0.60      0.79      0.61        19\n",
      "         32       0.49      0.47      0.99      0.48      0.68      0.44        55\n",
      "         33       0.74      0.69      1.00      0.72      0.83      0.67        42\n",
      "         35       0.71      0.45      1.00      0.56      0.67      0.43        11\n",
      "         36       0.33      0.67      1.00      0.44      0.82      0.64         3\n",
      "         37       0.67      1.00      1.00      0.80      1.00      1.00         2\n",
      "         38       0.87      0.80      1.00      0.83      0.89      0.78        49\n",
      "         39       0.62      1.00      1.00      0.77      1.00      1.00         5\n",
      "         41       0.88      0.78      1.00      0.82      0.88      0.76        18\n",
      "         42       0.62      0.57      1.00      0.59      0.75      0.54        23\n",
      "         43       0.65      0.68      1.00      0.67      0.82      0.66        25\n",
      "         45       0.68      0.79      1.00      0.73      0.89      0.77        33\n",
      "         46       0.67      0.72      0.99      0.70      0.84      0.69       100\n",
      "         47       0.52      0.42      0.99      0.46      0.64      0.39        53\n",
      "         49       0.62      0.81      0.99      0.70      0.90      0.79        31\n",
      "         50       0.88      0.75      1.00      0.81      0.87      0.73        20\n",
      "         51       0.83      0.91      1.00      0.87      0.95      0.90        11\n",
      "         52       0.62      0.54      1.00      0.58      0.73      0.51        28\n",
      "         53       1.00      0.75      1.00      0.86      0.87      0.73         8\n",
      "         55       1.00      0.67      1.00      0.80      0.82      0.64         9\n",
      "         56       0.70      0.78      1.00      0.74      0.88      0.76         9\n",
      "         58       0.68      0.73      0.99      0.71      0.85      0.71        41\n",
      "         59       0.54      0.60      0.99      0.57      0.77      0.57        25\n",
      "         60       0.67      0.57      1.00      0.62      0.76      0.55         7\n",
      "         61       0.94      1.00      1.00      0.97      1.00      1.00        17\n",
      "         62       0.33      0.30      1.00      0.32      0.55      0.28        10\n",
      "         63       0.71      0.50      1.00      0.59      0.71      0.47        10\n",
      "         64       0.68      0.74      1.00      0.71      0.86      0.72        23\n",
      "         65       0.84      0.87      1.00      0.85      0.93      0.85        30\n",
      "         66       0.33      0.44      0.99      0.38      0.66      0.42        18\n",
      "         68       1.00      1.00      1.00      1.00      1.00      1.00        15\n",
      "         69       0.38      0.27      1.00      0.32      0.52      0.25        11\n",
      "         70       0.75      0.67      1.00      0.71      0.82      0.64         9\n",
      "         71       0.64      0.70      1.00      0.67      0.83      0.67        23\n",
      "         72       0.93      1.00      1.00      0.96      1.00      1.00        38\n",
      "         73       0.89      0.67      1.00      0.76      0.82      0.64        12\n",
      "         74       0.50      0.47      1.00      0.49      0.69      0.45        19\n",
      "         75       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "         77       0.56      0.43      1.00      0.49      0.66      0.41        23\n",
      "         78       0.41      0.70      1.00      0.52      0.84      0.68        10\n",
      "         79       0.62      0.73      1.00      0.67      0.85      0.71        11\n",
      "         80       0.50      0.60      1.00      0.55      0.77      0.58         5\n",
      "         81       0.33      0.18      1.00      0.24      0.43      0.17        11\n",
      "         82       0.00      0.00      1.00      0.00      0.00      0.00        11\n",
      "         84       0.52      0.59      1.00      0.55      0.77      0.56        22\n",
      "         85       0.80      0.83      1.00      0.81      0.91      0.81        29\n",
      "         86       0.83      0.62      1.00      0.71      0.79      0.60        16\n",
      "         87       0.27      0.43      1.00      0.33      0.65      0.40         7\n",
      "         88       0.70      0.58      1.00      0.64      0.76      0.56        12\n",
      "         90       0.83      1.00      1.00      0.91      1.00      1.00         5\n",
      "         91       0.33      0.17      1.00      0.22      0.41      0.15         6\n",
      "         92       1.00      0.83      1.00      0.91      0.91      0.82         6\n",
      "         93       0.27      0.30      1.00      0.29      0.55      0.28        10\n",
      "         94       0.73      0.79      1.00      0.76      0.89      0.77        14\n",
      "         95       0.22      0.20      1.00      0.21      0.45      0.18        10\n",
      "         96       0.33      0.31      1.00      0.32      0.56      0.29        16\n",
      "         97       1.00      1.00      1.00      1.00      1.00      1.00         2\n",
      "         98       0.33      0.50      1.00      0.40      0.71      0.47         2\n",
      "         99       0.00      0.00      1.00      0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.68      0.67      0.99      0.67      0.81      0.65      2574\n",
      "\n",
      "C:\\Users\\annoc\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report_imbalanced(y_train_cat2, y_train_pred_for2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel classification\n",
    "This is where there is more than one class. So in our case, we could check for Category_0 and Category_1. However, each category_1 class always belongs to the same Category_0 class, so this is a special case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "\n",
    "y_train_C = (y_train_cat1 == 'C')\n",
    "y_train_2 = (y_train_cat0 == 2)\n",
    "\n",
    "y_multilabel = np.c_[y_train_C, y_train_2]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True,  True]])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "knn_clf.predict([test_item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.931940675708821"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "## This code computes the average F1 score across all labels: it can take a long time but not here.\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train_cat1, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9321046659125645"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "## This time it's a weighted average across all labels\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"weighted\")"
   ]
  },
  {
   "source": [
    "#### I presume it's ok to use the imbalanced learn metrics here too..   \n",
    "... acutally, no:   \n",
    "ValueError: imblearn does not support multilabel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_C = (y_train_cat1 == 'C')\n",
    "y_train_2 = (y_train_cat0 == 2)\n",
    "y_train_10 = (y_train_cat2 == 10)\n",
    "\n",
    "y_multilabel = np.c_[y_train_C, y_train_2, y_train_10]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train_cat1, y_multilabel, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9211046676852388"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "f1_score(y_multilabel, y_train_knn_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ True,  True,  True]])"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "knn_clf.predict([test_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(weights='distance', n_neighbors=4)\n",
    "knn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_knn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "def shift_digit(digit_array, dx, dy, new=0):\n",
    "    return shift(digit_array.reshape(28, 28), [dy, dx], cval=new).reshape(784)\n",
    "\n",
    "plot_digit(shift_digit(some_digit, 5, 1, new=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300000, 784), (300000,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_expanded = [X_train]\n",
    "y_train_expanded = [y_train]\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    shifted_images = np.apply_along_axis(shift_digit, axis=1, arr=X_train, dx=dx, dy=dy)\n",
    "    X_train_expanded.append(shifted_images)\n",
    "    y_train_expanded.append(y_train)\n",
    "\n",
    "X_train_expanded = np.concatenate(X_train_expanded)\n",
    "y_train_expanded = np.concatenate(y_train_expanded)\n",
    "X_train_expanded.shape, y_train_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train_expanded, y_train_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_knn_expanded_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_knn_expanded_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24579675, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.75420325]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguous_digit = X_test[2589]\n",
    "knn_clf.predict_proba([ambiguous_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD8CAYAAAC8aaJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABzNJREFUeJzt3b2PjP0ex/HdE7FhPYdCo6DxEInQ3GRVbKwQ/gAdhYpirVAoRAihIYhEEFRCoxFBRylCokCh8BBRKFY0CPauzjmJY75zdmb3HvbzepU+ueaaiHeu4mdmukdGRrqAHP/q9BsA/lmihzCihzCihzCihzCihzCTOnRf54Qw/rp/9Yee9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBG9BBmUqffAP/17t27cl+/fn25P3v2rOV7DwwMlPvatWvLfWhoqNwnT5486vfE+PCkhzCihzCihzCihzCihzCihzDdIyMjnbhvR27aadevXy/3I0eOlPvTp0/H8u2MSrN/J9OnTy/37u7uhtvSpUvLa/fv31/uW7duLfdgv/xL96SHMKKHMKKHMKKHMKKHMKKHMKKHMM7px9Dhw4fb2r9+/drW/fv6+hpuixYtauu1L1++XO7VOXy7enp6yn3fvn3lvn379obbggULWnpPfwjn9IDoIY7oIYzoIYzoIYzoIYzoIYxz+jG0ZMmScn/x4kVbr79ly5Zyv3LlSsNt5syZbd17cHCw3E+ePNnya/f395f7w4cPy314eLjcV6xY0XC7efNmee0ffo7vnB4QPcQRPYQRPYQRPYQRPYQRPYTxU9WjdOrUqYbbq1ev2nrtZt/ffunSpXJv9yy+Mm/evLau37RpU8Ot2e8B7Nixo9yvXbtW7k+ePGm4Nfs7PXjwYLn/iTzpIYzoIYzoIYzoIYzoIYzoIYzoIYxz+p80+3x19VvpX758Ka9dtWpVuV+8eLHcZ8+eXe7j6c2bN21dP3fu3IbblClTymvPnDlT7s2+p+Dx48cNN+f0wIQneggjeggjeggjeggjegjjyO4nb9++Lfdmx3KVZkduc+bMafm1x9u5c+fKvdlPVW/btq3lezf7e9m1a1e5Vz9V/eHDh/La27dvl/vGjRvL/XfkSQ9hRA9hRA9hRA9hRA9hRA9hRA9hnNPT1dXV/Guom2n2c9Nr1qxp6/UrS5cubfnaz58/l/vLly9bfu3flSc9hBE9hBE9hBE9hBE9hBE9hBE9hHFOH+Ljx4/lfuLEibZef2hoqNynTp3a1utX2vmOg0Se9BBG9BBG9BBG9BBG9BBG9BBG9BDGOf0EUp3Fr1+/vrz20aNHbd37r7/+auv6dhw6dKjla2fOnFnu4/k9AJ3iSQ9hRA9hRA9hRA9hRA9hRA9hRA9hnNP/ZNWqVeU+bdq0htunT5/Ka+/du1fuzX7jvZOa/U779OnT/6F38r9+/PhR7iMjIw233t7e8tqVK1e29J5+Z570EEb0EEb0EEb0EEb0EEb0EMaR3U9Wr15d7rdu3Wq4bd26tbx2eHi4pfc0Fnp6esr9xo0b5T4wMDCWb2dUjh49Wu4PHjwo9+oodCJ+dLYZT3oII3oII3oII3oII3oII3oII3oI45x+lNauXdtw27lzZ3nt+/fvy/3OnTvlvnjx4nJfvnx5w23//v3ltfPnzy/3Trp582a5f/v2rdyrr7nevXt3S+/pT+ZJD2FED2FED2FED2FED2FED2FED2Gc04+hZp/7bubNmzflPmvWrHLv5NdQN/P69euG29WrV8trnz592ta9+/v7G259fX1tvfafyJMewogewogewogewogewogewogewnRXP+M7jjpyU8ZPs/9jcPbs2Ybb8ePH27r3smXLyv3+/fsNt9mzZ7d179/cL7/w35MewogewogewogewogewogewvhoLf+Xd+/elfvmzZvLvZ2PxzY7kjtw4EC5T/BjuVHzpIcwoocwoocwoocwoocwoocwoocwPlob4vv37+V++vTpcj9//ny5P3/+fNTv6d9mzJhR7g8ePCj36ie6w/loLSB6iCN6CCN6CCN6CCN6CCN6COPz9BNIdRZffQV1V1dX1+DgYLk3+/8c3d2/PBL+j97e3obbhQsXymudw48tT3oII3oII3oII3oII3oII3oII3oI4/P0E0j13fQLFy4sr/369Wu5N/t3smHDhnLfu3dvw23dunXltbTM5+kB0UMc0UMY0UMY0UMY0UMY0UMY5/Qh7t69W+7Hjh0r9/7+/nLfs2dPuU+ePLncGRfO6QHRQxzRQxjRQxjRQxjRQxhHdjBxObIDRA9xRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hRA9hJnXovr/8nC8w/jzpIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIYzoIczf1V0jqpOLiWAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_digit(ambiguous_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An MNIST Classifier With Over 97% Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the next cell may take hours to run, depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.9717617659308622, total=10.9min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 52.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.9706715547408765, total=10.7min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 103.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_neighbors=3, weights=uniform, score=0.9689166666666666, total=10.1min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV]  n_neighbors=3, weights=uniform, score=0.968575477202634, total=11.0min\n",
      "[CV] n_neighbors=3, weights=uniform ..................................\n",
      "[CV]  n_neighbors=3, weights=uniform, score=0.9704068022674225, total=11.0min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.9723448563098709, total=10.9min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.9716713881019831, total=11.2min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.9700833333333333, total= 9.9min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.9700758522964075, total=10.0min\n",
      "[CV] n_neighbors=3, weights=distance .................................\n",
      "[CV]  n_neighbors=3, weights=distance, score=0.971407135711904, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.9690129112869638, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.9682552907848692, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.9675833333333334, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.9673251646244895, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=uniform ..................................\n",
      "[CV]  n_neighbors=4, weights=uniform, score=0.970323441147049, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.9730112453144523, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.9722546242292951, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.9699166666666666, total= 9.9min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.9709093940151705, total=10.5min\n",
      "[CV] n_neighbors=4, weights=distance .................................\n",
      "[CV]  n_neighbors=4, weights=distance, score=0.9719906635545181, total=10.7min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.9697625989171179, total=10.9min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.9701716380603232, total=10.5min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.9694166666666667, total=10.5min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.9681587063432525, total=10.7min\n",
      "[CV] n_neighbors=5, weights=uniform ..................................\n",
      "[CV]  n_neighbors=5, weights=uniform, score=0.9689896632210737, total=10.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.9703456892961266, total=10.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.9713381103149475, total=11.1min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.9704166666666667, total=10.4min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.969409018921397, total=10.6min\n",
      "[CV] n_neighbors=5, weights=distance .................................\n",
      "[CV]  n_neighbors=5, weights=distance, score=0.9706568856285428, total=12.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 1523.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'weights': ['uniform', 'distance'], 'n_neighbors': [3, 4, 5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'weights': [\"uniform\", \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716166666666667"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[1000]\n",
    "shifted_image_down = shift_image(image, 0, 5)\n",
    "shifted_image_left = shift_image(image, -5, 0)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Original\", fontsize=14)\n",
    "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(132)\n",
    "plt.title(\"Shifted down\", fontsize=14)\n",
    "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.subplot(133)\n",
    "plt.title(\"Shifted left\", fontsize=14)\n",
    "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_augmented = [image for image in X_train]\n",
    "y_train_augmented = [label for label in y_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(X_train, y_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train_augmented, y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By simply augmenting the data, we got a 0.5% accuracy boost. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tackle the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict whether or not a passenger survived based on attributes such as their age, sex, passenger class, where they embarked and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, login to [Kaggle](https://www.kaggle.com/) and go to the [Titanic challenge](https://www.kaggle.com/c/titanic) to download `train.csv` and `test.csv`. Save them to the `datasets/titanic` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TITANIC_PATH = os.path.join(\"datasets\", \"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is already split into a training set and a test set. However, the test data does *not* contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data and upload them to Kaggle to see your final score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at the top few rows of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* **Pclass**: passenger class.\n",
    "* **Name**, **Sex**, **Age**: self-explanatory\n",
    "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
    "* **Ticket**: ticket id\n",
    "* **Fare**: price paid (in pounds)\n",
    "* **Cabin**: passenger's cabin number\n",
    "* **Embarked**: where the passenger embarked the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get more info to see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, the **Age**, **Cabin** and **Embarked** attributes are sometimes null (less than 891 non-null), especially the **Cabin** (77% are null). We will ignore the **Cabin** for now and focus on the rest. The **Age** attribute has about 19% null values, so we will need to decide what to do with them. Replacing null values with the median age seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yikes, only 38% **Survived**. :(  That's close enough to 40%, so accuracy will be a reasonable metric to evaluate our model.\n",
    "* The mean **Fare** was £32.20, which does not seem so expensive (but it was probably a lot of money back then).\n",
    "* The mean **Age** was less than 30 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the target is indeed 0 or 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a quick look at all the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: Pclass, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: the code below uses a mix of `Pipeline`, `FeatureUnion` and a custom `DataFrameSelector` to preprocess some columns differently.  Since Scikit-Learn 0.20, it is preferable to use a `ColumnTransformer`, like in the previous chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build our preprocessing pipelines. We will reuse the `DataframeSelector` we built in the previous chapter to select specific attributes from the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the pipeline for the numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Age\", \"SibSp\", \"Parch\", \"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [28.    ,  1.    ,  2.    , 23.45  ],\n",
       "       [26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need an imputer for the string categorical columns (the regular `SimpleImputer` does not work on those):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build the pipeline for the categorical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Pclass\", \"Sex\", \"Embarked\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's join the numerical and categorical pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have a nice preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [38.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [26.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [28.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [26.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [32.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget to get the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a classifier. Let's start with an `SVC`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our model is trained, let's use it to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess_pipeline.transform(test_data)\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we could just build a CSV file with these predictions (respecting the format excepted by Kaggle), then upload it and hope for the best. But wait! We can do better than hope. Why don't we use cross-validation to have an idea of how good our model is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365250822835092"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, over 73% accuracy, clearly better than random chance, but it's not a great score. Looking at the [leaderboard](https://www.kaggle.com/c/titanic/leaderboard) for the Titanic competition on Kaggle, you can see that you need to reach above 80% accuracy to be within the top 10% Kagglers. Some reached 100%, but since you can easily find the [list of victims](https://www.encyclopedia-titanica.org/titanic-victims/) of the Titanic, it seems likely that there was little Machine Learning involved in their performance! ;-) So let's try to build a model that reaches 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a `RandomForestClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8149526160481217"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of just looking at the mean accuracy across the 10 cross-validation folds, let's plot all 10 scores for each model, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores (thanks to Nevin Yilmaz for suggesting this visualization). Note that the `boxplot()` function detects outliers (called \"fliers\") and does not include them within the whiskers. Specifically, if the lower quartile is $Q_1$ and the upper quartile is $Q_3$, then the interquartile range $IQR = Q_3 - Q_1$ (this is the box's height), and any score lower than $Q_1 - 1.5 \\times IQR$ is a flier, and so is any score greater than $Q3 + 1.5 \\times IQR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve this result further, you could:\n",
    "* Compare many more models and tune hyperparameters using cross validation and grid search,\n",
    "* Do more feature engineering, for example:\n",
    "  * replace **SibSp** and **Parch** with their sum,\n",
    "  * try to identify parts of names that correlate well with the **Survived** attribute (e.g. if the name contains \"Countess\", then survival seems more likely),\n",
    "* try to convert numerical attributes to categorical attributes: for example, different age groups had very different survival rates (see below), so it may help to create an age bucket category and use it instead of the age. Similarly, it may be useful to have a special category for people traveling alone since only 30% of them survived (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeBucket</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.362745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.423256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>0.404494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.0</th>\n",
       "      <td>0.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.0</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Survived\n",
       "AgeBucket          \n",
       "0.0        0.576923\n",
       "15.0       0.362745\n",
       "30.0       0.423256\n",
       "45.0       0.404494\n",
       "60.0       0.240000\n",
       "75.0       1.000000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"AgeBucket\"] = train_data[\"Age\"] // 15 * 15\n",
    "train_data[[\"AgeBucket\", \"Survived\"]].groupby(['AgeBucket']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelativesOnboard</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.552795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Survived\n",
       "RelativesOnboard          \n",
       "0                 0.303538\n",
       "1                 0.552795\n",
       "2                 0.578431\n",
       "3                 0.724138\n",
       "4                 0.200000\n",
       "5                 0.136364\n",
       "6                 0.333333\n",
       "7                 0.000000\n",
       "10                0.000000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"RelativesOnboard\"] = train_data[\"SibSp\"] + train_data[\"Parch\"]\n",
    "train_data[[\"RelativesOnboard\", \"Survived\"]].groupby(['RelativesOnboard']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spam classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load all the emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Python's `email` module to parse these emails (this handles headers, encoding, and so on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one example of ham and one example of spam, to get a feel of what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin A posted:\n",
      "Tassos Papadopoulos, the Greek sculptor behind the plan, judged that the\n",
      " limestone of Mount Kerdylio, 70 miles east of Salonika and not far from the\n",
      " Mount Athos monastic community, was ideal for the patriotic sculpture. \n",
      " \n",
      " As well as Alexander's granite features, 240 ft high and 170 ft wide, a\n",
      " museum, a restored amphitheatre and car park for admiring crowds are\n",
      "planned\n",
      "---------------------\n",
      "So is this mountain limestone or granite?\n",
      "If it's limestone, it'll weather pretty fast.\n",
      "\n",
      "------------------------ Yahoo! Groups Sponsor ---------------------~-->\n",
      "4 DVDs Free +s&p Join Now\n",
      "http://us.click.yahoo.com/pt6YBB/NXiEAA/mG3HAA/7gSolB/TM\n",
      "---------------------------------------------------------------------~->\n",
      "\n",
      "To unsubscribe from this group, send an email to:\n",
      "forteana-unsubscribe@egroups.com\n",
      "\n",
      " \n",
      "\n",
      "Your use of Yahoo! Groups is subject to http://docs.yahoo.com/info/terms/\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help wanted.  We are a 14 year old fortune 500 company, that is\n",
      "growing at a tremendous rate.  We are looking for individuals who\n",
      "want to work from home.\n",
      "\n",
      "This is an opportunity to make an excellent income.  No experience\n",
      "is required.  We will train you.\n",
      "\n",
      "So if you are looking to be employed from home with a career that has\n",
      "vast opportunities, then go:\n",
      "\n",
      "http://www.basetel.com/wealthnow\n",
      "\n",
      "We are looking for energetic and self motivated people.  If that is you\n",
      "than click on the link and fill out the form, and one of our\n",
      "employement specialist will contact you.\n",
      "\n",
      "To be removed from our link simple go to:\n",
      "\n",
      "http://www.basetel.com/remove.html\n",
      "\n",
      "\n",
      "4139vOLW7-758DoDY1425FRhM1-764SMFc8513fCsLl40\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some emails are actually multipart, with images and attachments (which can have their own attachments). Let's look at the various types of structures we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the ham emails are more often plain text, while spam has quite a lot of HTML. Moreover, quite a few ham emails are signed using PGP, while no spam is. In short, it seems that the email structure is useful information to have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the email headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <12a1mailbot1@web.de>\n",
      "Delivered-To : zzzz@localhost.spamassassin.taint.org\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received : from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received : from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From : 12a1mailbot1@web.de\n",
      "Received : from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To : dcek1a1@netsgo.com\n",
      "Subject : Life Insurance - Why Pay More?\n",
      "Date : Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version : 1.0\n",
      "Message-ID : <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type : text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding : quoted-printable\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header,\":\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's probably a lot of useful information in there, such as the sender's email address (12a1mailbot1@web.de looks fishy), but we will just focus on the `Subject` header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life Insurance - Why Pay More?'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, before we learn too much about the data, let's not forget to split it into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's start writing the preprocessing functions. First, we will need a function to convert HTML to plain text. Arguably the best way to do this would be to use the great [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) library, but I would like to avoid adding another dependency to this project, so let's hack a quick & dirty solution using regular expressions (at the risk of [un̨ho͞ly radiańcé destro҉ying all enli̍̈́̂̈́ghtenment](https://stackoverflow.com/a/1732454/38626)). The following function first drops the `<head>` section, then converts all `<a>` tags to the word HYPERLINK, then it gets rid of all HTML tags, leaving only the plain text. For readability, it also replaces multiple newlines with single newlines, and finally it unescapes html entities (such as `&gt;` or `&nbsp;`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works. This is HTML spam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                    if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the resulting plain text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's write a function that takes an email as input and returns its content as plain text, whatever its format is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except: # in case of encoding issues\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html_to_plain_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Wat ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's throw in some stemming! For this to work, you need to install the Natural Language Toolkit ([NLTK](http://www.nltk.org/)). It's as simple as running the following command (don't forget to activate your virtualenv first; if you don't have one, you will likely need administrator rights, or use the `--user` option):\n",
    "\n",
    "`$ pip3 install nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))\n",
    "except ImportError:\n",
    "    print(\"Error: stemming requires the NLTK module.\")\n",
    "    stemmer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need a way to replace URLs with the word \"URL\". For this, we could use hard core [regular expressions](https://mathiasbynens.be/demo/url-regex) but we will just use the [urlextract](https://github.com/lipoja/URLExtract) library. You can install it with the following command (don't forget to activate your virtualenv first; if you don't have one, you will likely need administrator rights, or use the `--user` option):\n",
    "\n",
    "`$ pip3 install urlextract`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running this notebook on Colab, we just pip install urlextract\n",
    "try:\n",
    "    import google.colab\n",
    "    !pip install -q -U urlextract\n",
    "except ImportError:\n",
    "    pass # not running on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urlextract # may require an Internet connection to download root domain names\n",
    "    \n",
    "    url_extractor = urlextract.URLExtract()\n",
    "    print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))\n",
    "except ImportError:\n",
    "    print(\"Error: replacing URLs requires the urlextract module.\")\n",
    "    url_extractor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to put all this together into a transformer that we will use to convert emails to word counters. Note that we split sentences into words using Python's `split()` method, which uses whitespaces for word boundaries. This works for many written languages, but not all. For example, Chinese and Japanese scripts generally don't use spaces between words, and Vietnamese often uses spaces even between syllables. It's okay in this exercise, because the dataset is (mostly) in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this transformer on a few emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
       "       Counter({'url': 5, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks about right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the word counts, and we need to convert them to vectors. For this, we will build another transformer whose `fit()` method will build the vocabulary (an ordered list of the most common words) and whose `transform()` method will use the vocabulary to convert word counts to vectors. The output is a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [99, 11,  9,  8,  1,  3,  3,  1,  3,  2,  3],\n",
       "       [65,  0,  1,  2,  5,  3,  1,  2,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this matrix mean? Well, the 99 in the second row, first column, means that the second email contains 99 words that are not part of the vocabulary. The 11 next to it means that the first word in the vocabulary is present 11 times in this email. The 9 next to it means that the second word is present 9 times, and so on. You can look at the vocabulary to know which words we are talking about. The first word is \"the\", the second word is \"of\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'url': 4,\n",
       " 'to': 5,\n",
       " 'all': 6,\n",
       " 'in': 7,\n",
       " 'christian': 8,\n",
       " 'on': 9,\n",
       " 'by': 10}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train our first spam classifier! Let's transform the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: to be future-proof, we set `solver=\"lbfgs\"` since this will be the default value in Scikit-Learn 0.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] .................................... , score=0.985, total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................... , score=0.9925, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9874999999999999"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 98.7%, not bad for a first try! :) However, remember that we are using the \"easy\" dataset. You can try with the harder datasets, the results won't be so amazing. You would have to try multiple models, select the best ones and fine-tune them using cross-validation, and so on.\n",
    "\n",
    "But you get the picture, so let's stop now, and just print out the precision/recall we get on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.88%\n",
      "Recall: 97.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ageron/.virtualenvs/tf2/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd019b1e62c464c24b664bf3bd8fed4c8880dd0d658beae74ca546300b2824c99fa",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}